#!/usr/bin/env python3
"""
This script produces reports on storage health (S.M.A.R.T) and passes it to mqtt publishing agent.
Utilizes 2 kinds of data collecting: nagios plugin and smartmontools
The MQTT hierarchy tree is pictured below. See .ini file for options with actual names
<root_topic> - root topic. nothing goes here
    <sd?> - named after /dev/sd? block device name.
        JSON serialized, high-level analysis of drive state going here:
        {
             these may go from smart or nagios plugin:
             "status":"OK or error message...",
             "checks run":count, - the number of different check procedure we ran (smart/nagios plugin/etc.)
             "checks with errors":count - and how many are failed
             these are from smart only:
             "model":"device model",
             "serial":"device S/N",
             "id":"device model + S/N. must be unique anyway",
             "type":"device type: HDD or SSD now"
             "tests done":count, - how many smart test are in log
             "tests failed":count, - and how many failed
        }
        <attributes_topic> - May contain JSON packed attributes here if topic defined in .ini
            id:{ "name":"...", "value":"...", "raw":"..." }
        <power_on_time> - lifetime hours (smart)
        <temperature> - degrees of C (smart)
        <error_log_topic> - JSON of raw error log entries (smart)
            { lifetime_hours:"error_description", ...  }
        <state_topic> - nagios-like: "OK", "WARNING", "CRITICAL"
        <raw_smart_topic> - unprocessed smart data
        <tests_log_topic> - JSON of raw tests log entries (smart)
            { lifetime_hours:"test status", ...  }
        <updated_topic> - When this device hierarchy was last updated:
            { "date":"Human readable date/time", "timestamp":UNIX_timestamp }

repo is in github.com/kadavris
Copyright by Andrej Pakhutin (pakhutin <at> gmail)
Provided under the terms of the GNU General Public License version 2 (GPL-2.0)
"""
import argparse
import configparser
import json
import os
import os.path
import re
import select
import shlex
import signal
import socket
import subprocess
import sys
import time
from typing import Any

known_dev_types = ['ata', 'sat', 'nvme', 'scsi']

#############################################################
def handle_termination(*_) -> None:
    """
    Tries to gracefully exit in case of problems

    param signum: UNUSED
    param frame: UNUSED
    :return: None
    """
    if sender:
        sender.terminate()

    sys.exit(0)


#############################################################
def load_config(c_file: str, default_path: str) -> None:
    """
    Loads .ini and may do some initializing of defaults

    :param c_file: str. Path to .ini file
    :param default_path: str. Last resort to find .ini
    :return: None
    """
    global args, config_full

    file = c_file

    if not os.path.exists(file):
        if file.find('/'):
            print("! Can't open config: " + file, file=sys.stderr)
            sys.exit(1)

        file = os.path.dirname(sys.argv[0]) + '/' + c_file

        if not os.path.exists(file):
            file = default_path + "/" + c_file

    if not os.path.exists(file):
        print("! Can't find your config anywhere", file=sys.stderr)
        sys.exit(1)

    if args.debug:
        print("+ Loading config:", file, file=sys.stderr)

    config_full = configparser.ConfigParser(interpolation=configparser.ExtendedInterpolation())
    config_full.read(file)

    if 'storage' not in config_full:
        print("! Config is missing 'storage' section!", file=sys.stderr)
        sys.exit(1)


########################################
def spawn_sender() -> None:
    """
    (Re)spawns process that actually sends mqtt messages to server

    :return: None
    """
    global args, config, sender

    if args.debug:
        print("+ Spawning sender process:", config['sender'], file=sys.stderr)

    sender=subprocess.Popen(shlex.split(config['sender']), bufsize=1,
                              # default buf size may gobble a whole loop of data and do nothing till the next
                              stdin=subprocess.PIPE,
                              stdout=None if args.debug or config['sender'].find('--debug')
                              else subprocess.STDOUT,
                              stderr=None if args.debug or config['sender'].find('--debug')
                              else subprocess.DEVNULL,
                              shell=False, text=True)

    if sender.poll():  # poll() return None if process is still there
        print('? ERROR with running ', sender.args, ": exited ",
              ("abnormally" if sender.returncode > 0 else "W/O error code"),
              "with rc:", sender.returncode, file=sys.stderr)
        sys.exit(1)

    time.sleep(3.0)  # trying to debug some strange re-connection issues


########################################
def send_message_raw(msg: str) -> None:
    """
    Sends another message to the spawned mqtt agent

    :param msg: string. sent as is
    :return: None
    """
    global sender

    try_number = 1
    while True:
        if sender.poll():  # check if it is still alive (not None)
            spawn_sender()

        if args.debug:
            print('> Sending:', msg)

        try:
            sender.stdin.write(msg)
            sender.stdin.write("\n")
        except:
            if args.debug:
                exc_type, exc_val, traceback = sys.exc_info()
                # if exc_val:
                #     exc_val = ','.join(exc_val.args)
                # else:
                #     exc_val = 'UNKNOWN REASON'
                print("! Sending failed (", exc_val, ")", file=sys.stderr)

            try_number += 1
            if try_number > 3:
                try_number = 1
                print("!!! Respawning.", file=sys.stderr)
                spawn_sender()
        else:
            break

        # waiting for 3 sec for answer
        if sender.stdout:
            answer = ''
            # gobble previous answers before checking last RC
            while select.select([sender.stdout], [None], [None], 3)[0][0] > 0:
                answer = sender.stdout.readline()

                if args.debug:
                    print('< Answer:', answer)

            if not answer.find('"rc":0'):
                print(time.localtime(), "!ERROR processing packet: ", ''.join(msg),
                      file=sys.stderr)
        else:
            time.sleep(3.0)  # let it process then


########################################
def send_message(*in_msg: str) -> None:
    """
    Sends another message to the spawned mqtt agent

    :param in_msg: list of strings: parts of the message
    :return: None
    """

    # our standard sending tool expect either one-line json
    # or back-slash terminated multiline one
    msg = re.sub(r"([^\\])\n", "\\1\\\n", "".join(in_msg))

    send_message_raw(msg)


########################################
def send_long(topic: str, *msg: str) -> None:
    """
    Sends complex message to the mqtt agent

    :param topic: topic name
    :param msg: list of strings
    :return: None
    """
    global config
    
    # this should be a highly unique stuff really
    stop_word = config["stop word"] if "stop word" in config else "3%g3h@544/ujW^r}gj" 

    send_message_raw('{ "mpublish":"' + stop_word + '", "retain":true,' +
                     ' "topics":[ "' + topic + '" ] }\n' + ''.join(msg) + stop_word)


########################################
def send_short(topic: str, *msg: str) -> None:
    """
    Posts a (short) message to a single topic

    :param topic: str. topic name
    :param msg: str list
    :return: 
    """
    send_message('{ "publish":"', ''.join(msg), '", "retain":true, "topics":[ "', topic, '" ] }')


########################################
def get_cygwin_mounts() -> None:
    """
    Collects windows mounted volumes information and put it into devices[] list
    under the 'mount' key in a form of '(C:,D:)'.
    Tailored for cygwin environment (fast)
    :return: None
    """
    global args, devices

    mf = open('/proc/partitions', 'r')

    while line := mf.readline():
        # major, minor, #blocks, name, win-mounts
        if rm := re.match(r'^\s*(\d+\s+){3}(sd[a-z])\d\s+([A-Z]:)', line):
            d = rm.group(2)
            dl = rm.group(3)
            if d not in devices:
                continue

            if devices[d]['mount'] == '':
                devices[d]['mount'] = '(' + dl
            else:
                devices[d]['mount'] += ',' + dl

    mf.close()

    for d in devices:
        if devices[d]['mount'] != "":
            devices[d]['mount'] += ')'


########################################
def get_win_mounts() -> None:
    """
    Collects windows mounted volumes information and put it into devices[] list
    under the 'mount' key in a form of '(C:,D:)'.
    Tailored for plain Windows environment (slow).
    To my view, this approach has benefit of being independent of installed modules etc.
    :return: None
    """
    global devices

    # This command will output the list of numbers for \.\PhysicalDrive,
    # then a list of drive letters assigned to particular PDs. Empty strings for ones w/o disk letter.
    params = ['powershell.exe', '-NoLogo', '-NonInteractive', '-Command',
              "(Get-Partition).DiskNumber;(Get-Partition).DriveLetter\n" ]
    try:
        ps = subprocess.Popen(params, stdout=subprocess.PIPE,
                              stderr=subprocess.PIPE, text=True, shell=False)

        if ps.poll():
            if ps.returncode > 0:
                print('PS run error: ended with rc: ' + str(ps.returncode), file=sys.stderr)
            return

        ret, err = ps.communicate()  # communicate() will return all output at once
        ps.terminate()
    except:
        return

    if err:
        return

    # split the output lines in half for the disk numbers and other half for drive letters
    l = ret.splitlines()
    half = len(l)//2

    for n in range(half):
        # According to man, smartctl maps X in non-existent /dev/sdX to the DiskNumber: a==0,b==1...
        sd_name = "sd" + chr(ord('a') + int(l[n].strip()))
        if sd_name not in devices:
            continue

        dlet = l[half + n][0:1]
        if dlet < "A" or dlet > "Z":
            continue

        if devices[sd_name]['mount'] == '':
            devices[sd_name]['mount'] = '(' + dlet + ':'
        else:
            devices[sd_name]['mount'] += ',' + dlet + ':'

        for d in devices:
            if devices[d]['mount'] != "":
                devices[d]['mount'] += ')'


########################################
def nested_keys_exists(in_hash: dict, *keys: str) -> bool:
    """
    Will check if _all_ nested keys (a path) exists in dict

    :param in_hash: top-level dict
    :param keys: array of sub-keys to dive into
    :returns True if path is valid
    """
    sub_hash = in_hash

    for key in keys:
        if key not in sub_hash:
            return False

        sub_hash = sub_hash[key]

    return True


########################################
def get_nested(default, tree: dict, *keys: str):
    """
    Scans tree for nested keys (a path )and return the final key's value or default if part of path was not found
    :param default: default value to return
    :param tree: dict with tree
    :param keys: list of sub-keys to scan
    :return: found key or default value
    """
    for k in keys:
        if k not in tree:
            return default
        tree = tree[k]

    return tree


########################################
def process_ata_attributes(sctl_json: dict, ret: dict, post_data: list | None) -> None:
    global args, config

    sctl_attr_table = sctl_json["ata_smart_attributes"]["table"]

    for sctl_attr in sctl_attr_table:
        if post_data:
            post_data.append(sctl_attr["id"] + ':{ "name":"' + sctl_attr["name"]
                                             + '", "value":"' + str(sctl_attr["value"])
                                             + '", "raw":"' + sctl_attr["raw"]["string"] + '" }')

        # check if value has crossed threshold.
        # The table format is <attribute #>: <bad values are less than threshold: bool>
        if sctl_attr["id"] in val_less_than_threshold:
            if (val_less_than_threshold[sctl_attr["id"]] and sctl_attr["value"] < sctl_attr["thresh"]) \
               or (not val_less_than_threshold[sctl_attr["id"]] and sctl_attr["value"] > sctl_attr["thresh"]):

                # determining the severity type of failed attribute
                err_or_warn_section = ""
                with sctl_attr["flags"] as flags:
                    if flags["prefailure"] or flags["error_rate"]:
                        err_or_warn_section = "errors"
                    elif flags["performance"] or flags["event_count"]:
                        err_or_warn_section = "warnings"

                msg = "Attribute's " + sctl_attr["name"] + " value (" + str(sctl_attr["value"]) \
                    + ") crossed threshold (" + str(sctl_attr["thresh"]) + ")"

                if "when_failed" in sctl_attr:
                    msg += " @ " + sctl_attr["when_failed"]

                if err_or_warn_section != "":
                    ret[err_or_warn_section].append(msg)
                    ret[err_or_warn_section + " count"] += 1

        # 190 Airflow_Temperature_Cel 0x0032   065   050   000    Old_age   Always       -       35
        if ret["temperature"] == -1 and (sctl_attr["id"] == 190 or sctl_attr["id"] == 194):
            ret["temperature"] = int(sctl_attr["value"])

        #  9 Power_On_Hours          0x0032   099   099   000    Old_age   Always       -       915 (222 63 0)
        # we'll use it to check if the tests are fresh enough
        elif ret["power on time"] == -1 and sctl_attr["id"] == 9:
            ret["power on time"] = int(sctl_attr["value"])


########################################
def process_nvme_attributes(sctl_json: dict, ret: dict, post_data: list | None) -> None:
    section = sctl_json["nvme_smart_health_information_log"]
    if count := section.get("critical_warning", 0) > 0:
        ret["errors"].append("Have " + str(count) + " critical warning(s)")
        ret["errors count"] += 1

    if section.get("available_spare", 100) < section.get("available_spare_threshold", 0):
        ret["warnings"].append("Available spare" + str(section.get("available_spare", 100)))
        ret["warnings count"] += 1

    if section.get("percentage_used", 0) > 80:
        ret["errors"].append("Media lifetime is at " + str(section.get("percentage_used", 0)) + "%")
        ret["errors count"] += 1

    if section.get("media_errors", 0):
        ret["errors"].append("Media errors at " + str(section.get("media_errors", 0)))
        ret["errors count"] += 1


########################################
def process_sctl_json(sctl_output_text: str, ret: dict, device_topic: str) -> bool:
    """
    This routine will parse the JSON formatted output from smartctl
    and will send processed stuff to the mqtt topics hierarchy (see top of file for explanation)
    NOTE: The combined state analysis will be posted in do_smartctl() final
    NOTE2: post_data is re-used to post large raw chunks of intermediate data to MQTT.
           E.g. attributes array if attributes_topic is configured

    :param sctl_output_text: raw smartctl output
    :param ret: returns the parsed data here - see do_smartctl for details
    :param device_topic: name of mqtt topics base for reports
    :return: bool: False if processing error were encountered
    """
    global args, config

    try:
        sctl_json = json.loads(sctl_output_text)
    except json.JSONDecodeError:
        return False

    if "model_name" not in sctl_json:
        ret["status"] = "drive is not compliant or smartctl returned incomplete data"
        return False

    if sctl_json["json_format_version"][0] != 1 and sctl_json["json_format_version"][1] != 0:
        ret["warnings"].append("Newer smartctl report version!")
        ret["warnings count"] += 1

    ret["model"] = sctl_json["model_name"]
    ret["serial"] = sctl_json["serial_number"]
    ret["id"] = sctl_json["model_name"] + " " + sctl_json["serial_number"]

    # retrieving specific model flags from config
    model_flags = sctl_json["model_name"].replace(" ", "")
    if model_flags in config:
        model_flags = config[model_flags].replace(" ", "").split("|")
    else:
        model_flags = []

    if get_nested("", sctl_json, "device", "type") == "nvme":
            ret["type"] = "NVMe"
    else:
        if get_nested(False, sctl_json, "trim", "supported"):
            ret["type"] = "SSD"
        else:
            ret["type"] = "HDD"

    ret["temperature"] = get_nested(-1, sctl_json, "temperature", "current")

    ret["power on time"] = get_nested(-1, sctl_json, "power_on_time", "hours")

    # Processing attributes
    if "attributes_topic" in config:  # we'll extract shorter attributes list for posting into separate topic
        post_data = []
    else:
        post_data = None

    if ret['type'] == "NVMe":
        process_nvme_attributes(sctl_json, ret, post_data)
    else:
        process_ata_attributes(sctl_json, ret, post_data)

    # Looking at the specific attributes here:

    if post_data:
        send_long(device_topic + '/' + config["attributes_topic"], "{\n", ",\n  ".join(post_data), "\n}")
        del sctl_json["ata_smart_attributes"]
    # End of attributes section

    # =============================================================
    # In this section we will check the error log for fresh entries

    if get_nested(0, sctl_json, "ata_smart_error_log", "summary", "logged_count") > 0:
        if "error_log_topic" in config:  # we'll extract shorter attributes list for posting into separate topic
            post_data = []
        else:
            post_data = None

        for elog in sctl_json["ata_smart_error_log"]["summary"]["table"]:
            if ret["power on time"] < elog["lifetime_hours"] + int(config["max_error_nag_hours"]):
                err_or_warn_section = "errors"  # still fresh
            else:
                err_or_warn_section = "warnings"  # to not lose them at all

            msg = elog["error_description"] + " @ " + str(elog["lifetime_hours"])

            if "previous_commands" in elog:
                msg += ", CMD: " + elog["previous_commands"][0]["command_name"]

            ret[err_or_warn_section].append(msg)
            ret[err_or_warn_section + " count"] += 1

            # record the age of earliest problem, so messages will be a bit more meaningful
            err_age_section = err_or_warn_section + " age"
            err_age = (int(ret["power on time"]) - int(elog["lifetime_hours"])) // 24
            if not err_age_section in ret or int(ret[err_age_section]) > err_age:
                ret[err_age_section] = str(err_age)

            if post_data:  # dedicated errors topic is set
                post_data.append(str(elog["lifetime_hours"]) + ':"'
                                 + elog["error_description"].replace('"', r'\"') + "}")

            if "previous_commands" in elog:
                msg += ", CMD: " + elog["previous_commands"][0]["command_name"]

    # posting error log analysis
    if post_data:
        send_long(device_topic + '/' + config["error_log_topic"], "{\n", ",\n  ".join(post_data), "\n}")
        del sctl_json["ata_smart_error_log"]

    # =============================================================
    #  In this section we check the tests log for problems
    if ret["type"] == "NVMe":
        tests_table = get_nested(None, sctl_json, "nvme_self_test_log", "table")
    else:
        tests_table = get_nested(
            get_nested(None, sctl_json, "ata_smart_self_test_log", "standard", "table"),
                                 sctl_json, "ata_smart_self_test_log", "extended", "table")

    if not tests_table:
        if "no_tests_log" not in model_flags:
            ret["testing status"] = "NO tests were recorded! Or test logging is not supported."
        else:
            if ret["testing status"] == "":
                ret["testing status"] = "OK"
    else:
        if "tests_log_topic" in config:  # we'll extract shorter attributes list for posting into separate topic
            post_data = []
        else:
            post_data = None

        last_short_test_age = sys.maxsize
        last_long_test_age = sys.maxsize

        # If a number of the last long tests were not finished, we report inconclusive state with count.
        # Flag initially set to True because it is reset on the 1st passed test record,
        # and yet we need to report first ones in list if some failed
        last_inconclusive = True

        if "short_test_log_time" in model_flags:  # if test log time is stored as uint16
            lifetime = ret["power on time"] % 65535
        else:
            lifetime = ret["power on time"]

        for tlog in tests_table:
            ret["tests done"] += 1
            if ret["type"] == "NVMe":
                test_type = tlog["self_test_code"]["value"]
                test_result = get_nested(-1, tlog, "self_test_result", "value")
                test_result_str = get_nested("", tlog, "self_test_result", "string")
                test_date = tlog["power_on_hours"]
            else:
                test_type = tlog["type"]["value"]
                test_result = get_nested(-1, tlog, "status", "value")
                test_result_str = get_nested("", tlog, "status", "string")
                test_date = tlog["lifetime_hours"]

            # test record may lack "passed" attribute if test has been interrupted.
            # we'll not count this at all, but report inconclusive if it is the latest one(s)
            if test_result != 0:
                if test_type == 2:  # only long ones count
                    if last_inconclusive:
                        ret["tests inconclusive"] += 1
                continue
            else:
                last_inconclusive = False  # don't report older, interrupted tests into inconclusive

            # recording the freshest test times in each category to report stale state or routine checks
            if lifetime < test_date: # happens on short int wrap
                tdiff = lifetime - (65535 - test_date)
            else:
                tdiff = lifetime - test_date

            if test_type == 1:  # Short offline
                if tdiff < last_short_test_age:
                    last_short_test_age = tdiff
            elif test_type == 2:  # Extended offline
                if tdiff < last_long_test_age:
                    last_long_test_age = tdiff

            if test_result != 0:
                ret["testing status"] += test_result_str + " @ " + str(test_date) + "\n"
                ret["tests failed"] += 1

                if post_data:
                    post_data.append(str(test_date) + ':"'
                                     + test_result_str.replace('"', r'\"') + '"')
        # end of test logs scan. preparing summary report

        # we'll report short tests problems if there are problems with long test too
        short_tests_status = ""

        max_tests_age = int(config["max_tests_age"])

        if last_short_test_age == sys.maxsize:
            short_tests_status = " and SHORT tests was NEVER run"
        else:
            if last_short_test_age > max_tests_age:
                short_tests_status = " and SHORT tests also didn't run for " \
                                     + str(round(last_short_test_age / 24)) + " days"

        if last_long_test_age == sys.maxsize:
            if ret["tests inconclusive"] > 0:
                ret["testing status"] = "ALL LONG tests were unfinished" + short_tests_status
            else:
                ret["testing status"] = "LONG tests was NEVER run" + short_tests_status
        else:
            if last_long_test_age > max_tests_age:
                ret["testing status"] = "LONG tests didn't run for " \
                        + str(round(last_long_test_age / 24)) \
                        + " days (max: " + str(round(max_tests_age / 24)) \
                        + ")" + short_tests_status

        if ret["testing status"] == "":
            ret["testing status"] = "OK"
        elif len(ret["testing status"]) > 254:
            ret["testing status"] = ret["testing status"][:250] + "..."

        if post_data:
            send_long(device_topic + '/' + config["tests_log_topic"], "{\n",
                      ",\n  ".join(post_data), "\n}")
            del sctl_json["ata_smart_error_log"]
    # done with test logs.

    if ret['type'] == "SSD":
        if nested_keys_exists(sctl_json, "endurance_used", "current_percent"):
            v = sctl_json["endurance_used"]["current_percent"]
            if v > 80:
                ret["errors"].append("Media lifetime is at " + str(v) + "%")
                ret["errors count"] += 1

    return True


########################################
def run_smartctl(device: str, *in_params) -> tuple[str, str]:
    """
    Prepares smartctl arguments and runs it

    :param device: device. can be empty to run global queries
    :param in_params: list of parameters
    :return: ( 'results string', 'error message if any' )
    """
    global args, config, devices

    # preparing smartctl parameters:
    params = [config["smartctl"]]
    params.extend(in_params)

    if device != '':
        # Hopefully should eliminate most of these:
        # "messages": [ { "string": "/dev/sdX: Unknown USB bridge [0xXXXX:0xXXXX]", "severity": "error" } ]
        if devices[device]["type"] == "usb":
            params.append("-d sat")
        elif devices[device]["type"] in ["sat"]:
            params.append("-d " + devices[device]["type"])

        # looking if there are specific smartctl switches to add
        for f in devices[device]["scopts"]:
            params.append(f)

        params.append("/dev/" + device)

    if args.debug:
        print("RUN: <", '> <'.join(params), '>', sep='', file=sys.stderr)

    sctl = subprocess.Popen(params, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                            text=True, shell=False)

    if sctl.poll():
        if sctl.returncode > 0:
            err = 'smartctl run error: ended with rc: ' + str(sctl.returncode)
            print(err)
            return '', err

        return '', 'smartctl run just failed'

    ret, err = sctl.communicate()  # communicate() will return all output at once
    sctl.terminate()

    return ret, err


########################################
def do_smartctl_proces(device: str, device_topic: str) -> dict:
    """
    Collects data from smartctl. Run parser. Post basic data.

    :param device: path to the device file
    :param device_topic: root topic for this device
    :return: hash made by process_sctl_json() or other low-level data processor
    """
    global args, config, devices

    ret = {  # pre-init and show what we want to get from smartctl
        "errors count": 0,    # total number of error conditions encountered
        "errors": [],         # array of detected errors as strings
        "id": "",             # unique id. model name + serial number
        "model": "",          # model name. if this is empty string then we had problems with json
        "power on time": -1,  # hours
        "serial": "",         # serial number
        "status": "",
        "temperature": -1,
        "testing status": "",  # a summary for testing procedures
        "tests done": 0,
        "tests failed": 0,
        "tests inconclusive": 0,  # some tests may have been interrupted and pass status is not available
        "type": "",           # "HDD" or "SSD" - loosely based on TRIM support and rotation speed
        "warnings count": 0,  # total number of warning conditions encountered
        "warnings": [],       # array of all warning conditions in string form
    }

    params = [ '-a', '-j' ]

    json_string, err = run_smartctl(device, *params)

    if err != "":
        ret["status"] = ',"smartctl error":"' + err + "'"
        print(ret["status"])
        return ret

    json_string.replace("\r\n", "\n")  # Fix win EOL

    process_sctl_json(json_string, ret, device_topic)

    # send raw smart data. doing this anyway even if output is invalid, so it gets visible
    if "raw_smart_topic" in config:
        send_long(device_topic + "/" + config["raw_smart_topic"], json_string)

    if ret["status"] == "":
        ret["status"] = "OK"

    return ret

########################################
def get_devices_list() -> None:
    """
    Will refresh a list of devices to get info from.
    Fills in the 'devices' dict
    :return: None
    """
    global args, config, devices

    # resetting with options saving
    dev_options = devices['options']
    devices = dict()
    dev_options['time'] = time.time()  # setting now if there will be errors on scan
    devices['options'] = dev_options

    if sys.platform == "linux":
        for device in os.listdir("/dev"):
            if not re.match("sd[a-z]$", device):
                continue

            # check if it is ata/SAT ones. Currently, seen variants:
            #   onboard:    /devices/pci0000:00/0000:00:12.0/ata1/host0/target0:0:0/0:0:0:0/block/sda
            #   addon card: /devices/pci0000:00/0000:00:14.0/0000:02:00.0/ata3/host2/target2:0:0/2:0:0:0/block/sdc
            #   USB drive:  /devices/pci0000:00/0000:00:15.0/usb2/2-2/2-2:1.0/host4/target4:0:0/4:0:0:0/block/sde
            # NOTE: reading major # from /sys/class/block/sd?/dev being a tad untidy as I think,
            #       but I have no SCSI and nvme drives to look at under linux.
            rm = re.search(r"/(ata|usb|scsi)\d+", os.readlink("/sys/class/block/" + device))
            if not rm:
                if args.debug:
                    print(device, "- not our type", file=sys.stderr)
                continue

            devices[device] = { 'type': rm.group(1).lower() }

    else:  # cygwin or windows native python, etc. doing slower scan
        dstr, err = run_smartctl('', '--scan')
        if err != '':
            print(err)
            return

        for line in dstr.splitlines():
            # /dev/sda -d ata  # /dev/sda, ATA device
            # /dev/sdd -d sat  # /dev/sdd [SAT], ATA device
            # /dev/sde -d scsi  # /dev/sde, SCSI device
            m = re.match(r'.dev.(sd.)\s+-d\s+(\S+)', line)
            device = m.group(1)
            dtype = m.group(2)

            devices[device] = { 'type': dtype.lower() }

    skiplist = config['skip_dev_types'].replace(' ', '').split(',')

    klist = list(devices.keys())
    for d in klist:
        if d == 'options':
            continue

        if devices[d]['type'] not in known_dev_types:
            if args.debug:
                print(d, "type strangely is", devices[d]['type'], file=sys.stderr)

            del devices[d]
            continue

        if devices[d]['type'] in skiplist:
            if args.debug:
                print(d, "- skipping by a skip_types rule", file=sys.stderr)

            del devices[d]
            continue

        devices[d]['mount'] = '' # we want to see real drive letter in windows. In Linux here may be mount points later
        print(d, "type", devices[d]['type'], file=sys.stderr) # report only usable ones

    if os.path.isdir('/cygdrive/c'): # now collect real drive letters for more handy reports
        get_cygwin_mounts()
    elif sys.platform[0:3] == "win":
        get_win_mounts()


########################################
def check_storage() -> None:
    """
    This function will:
    Make preparations like drives list and pre-flight.
    Calls configured data collector's drivin routine(s),
    Consolidates information about reported problems and posts to device's root topic

    Consult the beginning of this script for topics structure

    :return: None
    """
    global args, config, devices

    # refresh devices list every N min
    if devices['options']['time'] < time.time() - float(config["refresh_dev_list"]):
        get_devices_list()

    for dev_sd in devices:
        if dev_sd == 'options':
            continue

        if args.debug:
            print("+ device:", dev_sd, file=sys.stderr)

        device_topic = config["device_topic"].replace("$device", dev_sd)

        # we will count the configured checks to report if none were enabled actually
        checks_run = 0
        checks_with_errors = 0

        state = []  # we'll try to determine it by any test enabled
        severity = 0  # how bad troubles are. 0-OK, 1-warn, >1 - crit

        devinfo: dict = devices[dev_sd]

        # looking if there are specific model options
        if "model flags" not in devinfo:  # retrieving
            devinfo["model flags"] = []  # misc flags
            devinfo["scopts"] = []       # smartctl options if any

            try:
                devinfo["model"] = open("/sys/block/" + dev_sd + "/device/model").readline()
                m = devinfo["model"].replace(" ", "")

                if m in config:  # have a section in .ini
                    for f in config[m].split("|"):
                        if f[1:6] == "scopt=":
                            devinfo["scopts"].append(f[7:])
                        else:
                            devinfo["model flags"].append(f)
            except FileNotFoundError:  # (cyg)win has no /sys, but we'll get info from sctl output
                devinfo["model"] = "_"

        # doing nagios's check_ide_smart run if configured. it is really simple.
        if "check_ide_smart" in config:
            checks_run += 1
            params = shlex.split(config["check_ide_smart"])
            params.append("/dev/" + dev_sd)
            cis = subprocess.Popen(params, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)

            st, err = cis.communicate()  # communicate will slurp output and close pipe
            st = re.sub("^OK .*", "OK", st.rstrip())  # strip out clutter

            if st != "OK" or err != "":
                checks_with_errors += 1
                state.append(st + "(" + err + ")")
                severity += 1

        # doing smartctl run if configured
        if "smartctl" in config:
            checks_run += 1
            sctl_data = do_smartctl_proces(dev_sd, device_topic)

            if sctl_data["model"] == "UNKNOWN":
                if args.debug:
                    print("! smartctl failed to query:", dev_sd, devices[dev_sd]['mount'], file=sys.stderr)

                continue

            if sctl_data["testing status"] != "OK":  # failed or not running tests detected
                checks_with_errors += 1
                severity += 1

                state.append("testing status: " + sctl_data["testing status"])

            msg = json.dumps(sctl_data, skipkeys=True, separators=(',\n', ': '))

            if sctl_data["errors count"] > 0:
                state.append("Has " + str(sctl_data["errors count"]) + " current errors! Last occured "\
                             + str(sctl_data["errors age"]) + " day(s) ago")
                severity += sctl_data["errors count"] + 1

            if sctl_data["warnings count"] > 0:
                state.append("Has " + str(sctl_data["warnings count"]) + " issues. Last occured "\
                             + str(sctl_data["warnings age"]) + " day(s) ago")
                severity += sctl_data["warnings count"] / 10  # warnings are more or less old and stabilized state

            if sctl_data["tests failed"] > 0:
                state.append(str(sctl_data["tests failed"]) + " of " + str(sctl_data["tests done"])
                             + " recent tests failed!")
                severity += 1

            if sctl_data["tests inconclusive"] > 0:
                state.append(str(sctl_data["tests inconclusive"]) + " latest tests were not finished!")
                severity += 0.2

            if sctl_data["status"] != "OK":  # e.g. some value went below threshold - pre-fail state at least
                state.append(sctl_data["status"])
                severity += 2

            send_long(device_topic, msg)

            send_short(device_topic + "/" + config["temperature_topic"], str(sctl_data["temperature"]))

        if checks_run > 0:  # so we got something meaningful to report here
            if severity == 0:
                st = "OK"
            else:
                st = ("WARNING: " if severity < 2 else "CRITICAL: ") + devices[dev_sd]['mount'] + \
                     ", ".join(state).replace('"', r'\"')

            send_short(device_topic + "/" + config["state_topic"], st)

            send_short(device_topic + "/" + config['updated_topic'], dates_json)


####################################################
def set_config_default(key: str, val) -> None:
    """
    Initializes defaults in config

    :param key: key to look for
    :param val: default value to set
    :return: None
    """
    global config

    if key not in config:
        config[key] = str(val)


####################################################
global config_full, dates_json, root_topic, sender

# This is the list of known attributes where warning should be produced on val exceed threshold
# True when val < thresh is bad, False when val > threshold is bad
val_less_than_threshold = {
    "1": True, "2": False, "3": True, "5": True, "8": False,
    "10": True, "11": True, "13": True, "22": False,
    "181": True, "183": True, "184": True, "187": True, "188": True, "189": True,
    "191": True, "192": True, "193": True, "194": True, "196": True, "197": True, "198": True, "199": True,
    "200": True, "201": True, "202": True, "203": True, "204": True, "205": True, "207": True,
    "220": True, "221": True, "227": True, "228": True, "250": True, "254": True
}

def_config_path = "/etc/smarthome/monitoring/storage"  # defaults
def_config_file = def_config_path + "/mqtt-storage.ini"

####################################################

parser = argparse.ArgumentParser(
    description="Collect state info from the storage devices and post it to mqtt.\n"
                "V2.11. Copyright (c) 2022+ by Andrej Pakhutin")
parser.add_argument("-c", "--config", dest="config_path", action="store", default=def_config_file,
                    help="path to a non-default config file")
parser.add_argument("-d", "--debug", dest="debug", action="store_true", default=False, help="debug mode")
parser.add_argument("-l", "--loop", dest="loop", action="store", type=int, default=0,
                    help="Loop forever, sleeping <int> seconds between passes")
parser.add_argument("action", nargs="?", default="", help="non-default action name to run")

args = parser.parse_args()

load_config(args.config_path, def_config_path)
config = config_full['storage']

hba = socket.gethostbyaddr(socket.gethostname())
hostname = re.sub(r"\..+", "", hba[0])

# mqtt sender script tend to hang up (why no SIGPIPE on stdin read?) if we exit hastily.
signal.signal(signal.SIGINT, handle_termination)
signal.signal(signal.SIGTERM, handle_termination)

spawn_sender()

queue = []
mounts = dict()
devices: dict[str, Any] = { 'options': { 'time': 0.0 } }  # last refresh of a list

if args.action != "":
    queue.append(args.action)
else:
    queue = [check_storage]

#  Set some defaults:
set_config_default("max_error_nag_hours", 24 * 10)
set_config_default("max_inactivity", 10 * 60)
set_config_default("max_tests_age", 7 * 24)
set_config_default("skip_dev_types", "")
set_config_default("refresh_dev_list", "1800")

while True:
    dates_json = '{ "date":"' + time.ctime() + '", "timestamp":' + str(int(time.time())) + ' }'
    dates_json = dates_json.replace(r'"', r'\"')

    for func in queue:
        if sender.poll():
            if sender.returncode > 0:
                print("? NOTE:", sender.args, "exited abnormally with rc:", sender.returncode, file=sys.stderr)
                spawn_sender()
        func()

    if args.loop == 0:
        break

    time.sleep(args.loop)

sender.communicate(input="\n\n" + '{ "cmd":"exit" }' + "\n")

try:
    sender.wait(timeout=5.0)
except Exception:
    pass

sender.terminate()
